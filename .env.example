# =============================================================================
# EasySql Configuration
# =============================================================================
# Copy this file to .env and fill in your actual values
# NEVER commit .env to version control!

# =============================================================================
# Neo4j Configuration
# =============================================================================
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password
# Neo4j database name (requires Neo4j 4.0+, default: neo4j)
# Use different databases for project isolation
NEO4J_DATABASE=neo4j

# =============================================================================
# Milvus Configuration
# =============================================================================
MILVUS_URI=http://localhost:19530
# Optional: For Milvus Cloud or authentication
# MILVUS_TOKEN=your_milvus_token
# Collection name prefix for isolation (e.g., "medical" -> "medical_table_embeddings")
MILVUS_COLLECTION_PREFIX=

# =============================================================================
# Embedding Model Configuration
# =============================================================================
# Recommended models for Chinese:
#   - BAAI/bge-large-zh-v1.5 (1024 dim, best quality)
#   - BAAI/bge-base-zh-v1.5 (768 dim, balanced)
#   - BAAI/bge-small-zh-v1.5 (512 dim, fastest)
EMBEDDING_MODEL=BAAI/bge-large-zh-v1.5
EMBEDDING_DIMENSION=1024

# =============================================================================
# Source Database Configuration
# =============================================================================
# Format: DB_<NAME>_<PROPERTY>
# Supported types: mysql, postgresql

# Example MySQL database (HIS system)
DB_HIS_TYPE=mysql
DB_HIS_HOST=localhost
DB_HIS_PORT=3306
DB_HIS_USER=root
DB_HIS_PASSWORD=your_mysql_password
DB_HIS_DATABASE=his_db
DB_HIS_DESCRIPTION=医院信息管理系统

# Example PostgreSQL database (LIS system) - uncomment to enable
# DB_LIS_TYPE=postgresql
# DB_LIS_HOST=localhost
# DB_LIS_PORT=5432
# DB_LIS_USER=postgres
# DB_LIS_PASSWORD=your_pg_password
# DB_LIS_DATABASE=lis_db
# DB_LIS_SYSTEM_TYPE=LIS
# DB_LIS_DESCRIPTION=检验信息系统

# =============================================================================
# Pipeline Configuration
# =============================================================================
# Batch size for database operations
BATCH_SIZE=1000

# Enable/disable specific pipeline steps
ENABLE_SCHEMA_EXTRACTION=true
ENABLE_NEO4J_WRITE=true
ENABLE_MILVUS_WRITE=true

# =============================================================================
# Logging Configuration
# =============================================================================
LOG_LEVEL=INFO
LOG_FILE=logs/easysql.log

# =============================================================================
# Schema Retrieval Configuration (Text2SQL)
# =============================================================================
# Milvus search settings
RETRIEVAL_SEARCH_TOP_K=5
RETRIEVAL_EXPAND_FK=true
RETRIEVAL_EXPAND_MAX_DEPTH=1

# Semantic filter settings
SEMANTIC_FILTER_ENABLED=true
SEMANTIC_FILTER_THRESHOLD=0.5
SEMANTIC_FILTER_MIN_TABLES=3

# Core tables that should never be filtered (comma-separated)
CORE_TABLES=patient,employee,department,drug_dictionary,diagnosis_dictionary

# Bridge table protection
BRIDGE_PROTECTION_ENABLED=true
BRIDGE_MAX_HOPS=3

# =============================================================================
# LLM Filter Configuration (Optional - for highest precision)
# =============================================================================
# Enable LLM-based table filtering (adds latency but improves precision)
LLM_FILTER_ENABLED=false
LLM_FILTER_MAX_TABLES=8
LLM_FILTER_MODEL=deepseek-chat

# LLM API configuration (supports OpenAI-compatible APIs)
# For DeepSeek:
LLM_API_BASE=https://api.deepseek.com/v1
LLM_API_KEY=your_deepseek_api_key

# For OpenAI:
# LLM_API_BASE=https://api.openai.com/v1
# LLM_API_KEY=your_openai_api_key
# LLM_FILTER_MODEL=gpt-4o-mini

# =============================================================================
# LLM Layer Configuration (LangGraph Agent)
# =============================================================================

# Query Mode: 'plan' (Interactive/HITL) or 'fast' (Direct)
QUERY_MODE=plan

# LLM Provider: openai, google_genai, anthropic
LLM_PROVIDER=openai

# --- Provider Models & Keys ---

# OpenAI Config
OPENAI_API_KEY=your_openai_api_key
OPENAI_API_BASE=https://api.openai.com/v1

# Google Gemini Config
GOOGLE_API_KEY=your_google_ai_studio_key

# Anthropic Config
ANTHROPIC_API_KEY=your_anthropic_api_key

# MCP / Tool Config
# Optional: DBHub MCP Server URL (if using MCP for execution)
# MCP_DBHUB_URL=http://localhost:8080/mcp

# --- Model Selection ---
# Strong model for Planning/Thinking (plan mode, analyze, complex generation)
# Examples: gpt-4o, gemini-1.5-pro
MODEL_PLANNING=gpt-4o

# Fast model for Simple Tasks (fast mode, simple extraction)
# Examples: gpt-4o-mini, gemini-1.5-flash
MODEL_FAST=gpt-4o-mini
